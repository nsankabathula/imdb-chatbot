{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import sys \n",
    "import datetime as dt\n",
    "import time\n",
    "import gc\n",
    "#gc.collect()\n",
    "\n",
    "\n",
    "#http://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB SQLLite Database: ../data/imdb.sqllite\n"
     ]
    }
   ],
   "source": [
    "from helper.parallel_util import ParallelUtil\n",
    "from helper.parsers import Utils\n",
    "from helper.url_utils import UrlUtils\n",
    "from helper.file_mapping import FILE_MAPPINGS\n",
    "from helper.imdb_sqllite_db import IMDBSQLLite\n",
    "import config\n",
    "\n",
    "LESSON_DATA_FOLDER = config.IMDB_DATA_FOLDER\n",
    "NROWS = None\n",
    "imdb_db = IMDBSQLLite();\n",
    "imdbConn, imdbCurs = imdb_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters = ParallelUtil('./data/parallel.config.tsv')      \n",
    "#clusters.info()\n",
    "\n",
    "#UrlUtils.get_file_name('https://datasets.imdbws.com/name.basics.tsv.gz')\n",
    "#UrlUtils.is_downloadable('https://datasets.imdbws.com/name.basics.tsv.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Donwload latest imdb data files using config.IMDB_DATASETS\n",
    "\n",
    "for url in config.IMDB_DATASETS:\n",
    "    UrlUtils.download(url, config.IMDB_DATA_FOLDER)\n",
    "    print (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Load titles data\n",
    "df_titles = pd.read_table('../data/title.basics.tsv.gz', nrows = NROWS)\n",
    "df_titles.replace({'runtimeMinutes':{'\\\\N':0}, 'endYear':{'\\\\N':None}}, inplace= True, method='bfill')\n",
    "#df_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Load ratings data\n",
    "df_ratings = pd.read_table('../data/title.ratings.tsv.gz', nrows = NROWS)\n",
    "df_titles.replace({'\\\\N':None}, inplace= True, method='bfill')\n",
    "df_ratings.dropna(axis=0, how='all', inplace = True)\n",
    "#df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Load episode data\n",
    "df_episodes = pd.read_table('../data/title.episode.tsv.gz', nrows = NROWS)\n",
    "df_episodes.replace({'\\\\N':None}, inplace= True, method='bfill')\n",
    "df_episodes.dropna(axis=0, how='any', inplace = True)\n",
    "#df_episodes.to_sql(\"title_episodes\", imdbConn, if_exists=\"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Merge titles & ratings \n",
    "df_merged_title_ratings = df_titles.merge(df_ratings, on=['tconst'], how='left')\n",
    "df_merged_title_ratings = df_merged_title_ratings.merge(df_episodes[['tconst','parentTconst']], on=['tconst'], how='left')\n",
    "\n",
    "df_merged_title_ratings.replace({np.NaN:None}, inplace= True, method='bfill')\n",
    "#df_merged_title_ratings\n",
    "df_merged_title_ratings.to_sql(\"merged_title_ratings\", imdbConn, if_exists=\"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Destroy titles, ratings & merged dataframes.\n",
    "del [df_titles, df_ratings, df_merged_title_ratings, df_episodes]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Load names data\n",
    "NROWS = None\n",
    "df_names = pd.read_table('../data/name.basics.tsv.gz', nrows = NROWS)\n",
    "df_names.replace({'\\\\N':None}, inplace= True, method='bfill')\n",
    "#df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8: Load names principals\n",
    "df_principals = pd.read_table('../data/title.principals.tsv.gz', nrows = NROWS)\n",
    "df_principals.replace({'\\\\N':None}, inplace= True, method='bfill')\n",
    "#df_principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9: Merge names & principals \n",
    "df_merged = df_principals.merge(df_names, on=['nconst'], how='left')\n",
    "\n",
    "df_merged.replace({np.NaN:None}, inplace= True, method='bfill')\n",
    "#df_merged.head()\n",
    "df_merged.to_sql(\"merged_name_principals\", imdbConn, if_exists=\"replace\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10: Destroy titles, ratings & merged dataframes.\n",
    "del [df_names, df_principals, df_merged]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Drop & Create Indexes using config.IMDB_TABLE_DICT  \n",
    "def drop_create_table_index(tableName):\n",
    "    INDEX_DICT = config.IMDB_TABLE_DICT    \n",
    "    indexes = INDEX_DICT[tableName]['indexs']\n",
    "    for index in indexes:\n",
    "        imdb_db.createIndex(tableName = tableName, indexName = index['indexName'], columns = index['columns'], \n",
    "                            isUnique = index['isUnique'])\n",
    "\n",
    "drop_create_table_index('title_episodes')        \n",
    "drop_create_table_index('merged_title_ratings')      \n",
    "drop_create_table_index('merged_name_principals')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "print (imdb_db.rowCount('title_episodes'))    \n",
    "print (imdb_db.rowCount('merged_title_ratings'))    \n",
    "print (imdb_db.rowCount('merged_name_principals'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any Random Test you may want to.\n",
    "result = imdb_db.query('select  * from merged_title_ratings limit 100000');\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database or disk is full",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-16f9646b1cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimdbConn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VACUUM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: database or disk is full"
     ]
    }
   ],
   "source": [
    "imdbConn.execute(\"VACUUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
