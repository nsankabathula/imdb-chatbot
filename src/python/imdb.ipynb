{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import sys \n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "LESSON_DATA_FOLDER = './data/'\n",
    "#http://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingletonDecorator:\n",
    "    def __init__(self,klass):\n",
    "        self.klass = klass\n",
    "        self.instance = None\n",
    "    def __call__(self,*args,**kwds):\n",
    "        if self.instance == None:\n",
    "            self.instance = self.klass(*args,**kwds)\n",
    "        return self.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel\n",
    "import pandas\n",
    "\n",
    "class _ParallelUtil:\n",
    "            \n",
    "    def __init__(self):        \n",
    "        self.__CLUSTER_REQUESTS = 0\n",
    "        self.__CLUSTER_FAILURES = []      \n",
    "        self.__CLUSTERS = None\n",
    "        self.getCluster()\n",
    "        \n",
    "    @staticmethod\n",
    "    def __PARALLEL_CLUSTERS(throwError = False):\n",
    "        try:\n",
    "            PARALLEL_CONFIG = pandas.read_table(''.join([LESSON_DATA_FOLDER, 'parallel.config.tsv']))\n",
    "            PARALLEL_CONFIG.replace(to_replace={'None':None},method='pad', inplace=True)\n",
    "            default_config = PARALLEL_CONFIG[PARALLEL_CONFIG['default'] == True].to_dict('records')[0]\n",
    "            default_config\n",
    "\n",
    "\n",
    "            CLUSTERs = ipyparallel.Client(profile=default_config['profile'],sshserver=default_config['sshserver'],\n",
    "                                          password=default_config['password'])\n",
    "            print('PROFILE: {} || IDS: {} '.format(CLUSTERs.profile, CLUSTERs.ids))\n",
    "            #print(\"IDs:\", CLUSTER.ids) # Print process id numbers\n",
    "    \n",
    "            return CLUSTERs\n",
    "        except Exception as ex:            \n",
    "            print (ex)\n",
    "            if(throwError) :\n",
    "                raise\n",
    "            else:\n",
    "                pass\n",
    "                return None\n",
    "            \n",
    "                \n",
    "    def setImports(self):\n",
    "        clusters = self.getCluster()\n",
    "\n",
    "        dview = clusters[:]\n",
    "        with dview.sync_imports():\n",
    "            import pandas\n",
    "            import numpy\n",
    "            import datetime\n",
    "            import time\n",
    "                     \n",
    "    def getCluster(self):\n",
    "        if(self.__CLUSTERS == None):\n",
    "            try:\n",
    "                self.__CLUSTER_REQUESTS  = self.__CLUSTER_REQUESTS + 1\n",
    "                self.__CLUSTERS = _ParallelUtil.__PARALLEL_CLUSTERS(True)\n",
    "            except Exception as ex:   \n",
    "                self.__CLUSTER_FAILURES.append(ex)\n",
    "                pass\n",
    "            \n",
    "        return self.__CLUSTERS\n",
    "    \n",
    "    def info(self):\n",
    "        print ('CLUSTER_REQUESTS: {}, CLUSTER_FAILURES: {}'.format(self.__CLUSTER_REQUESTS, self.__CLUSTER_FAILURES))\n",
    "\n",
    "class ParallelUtil: pass\n",
    "ParallelUtil = SingletonDecorator(_ParallelUtil)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hub connection request timed out\n",
      "Hub connection request timed out\n"
     ]
    }
   ],
   "source": [
    "ParallelUtil().getCluster()\n",
    "#clusterUtil.info()\n",
    "#ParallelUtil.__PARALLEL_CLUSTERS(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "import numpy\n",
    "\n",
    "class Utils:\n",
    "    \n",
    "    @staticmethod\n",
    "    def index_array(length):\n",
    "        result = [x for x in range(length)]   \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_date(date):\n",
    "        if str(date) == '' or date == None:\n",
    "            return None\n",
    "        else:\n",
    "            return datetime.strptime(date,'%Y-%m-%d')    \n",
    "        \n",
    "    @staticmethod\n",
    "    def parse_int(i, defaultValue=None):    \n",
    "       # print (defaultValue)\n",
    "        if ( i == None or str(i) == '' or str(i) == 'NaN' or i == numpy.NaN) :\n",
    "            return defaultValue   \n",
    "        else:\n",
    "            try:\n",
    "                #print ('convert', int(i))\n",
    "                return int(float(i))\n",
    "            except:\n",
    "                return i\n",
    "            \n",
    "    @staticmethod\n",
    "    def parse_float(f):\n",
    "        if str(f) == '' or f == None:\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                return float(f)\n",
    "            except:\n",
    "                return f\n",
    "            \n",
    "    @staticmethod\n",
    "    def parse_bool(boolean):\n",
    "        if str(boolean) == '' or boolean == None:\n",
    "            return None\n",
    "        else:        \n",
    "            return boolean =='True' \n",
    "\n",
    "    @staticmethod\n",
    "    def split(data, delimiter=',' ):\n",
    "        #print ('data: ', data)    \n",
    "        if(data == '' or data == None or str(data) == None):\n",
    "            return np.array([None])\n",
    "        else:\n",
    "            #return np.array(str(data).lower().split(delimiter))    \n",
    "            lst = np.array(str(data).split(delimiter))       \n",
    "            return lst    \n",
    "\n",
    "    @staticmethod\n",
    "    def lower(data):\n",
    "        if(data == '' or data == None):\n",
    "            return None\n",
    "        else:\n",
    "            return str(data).lower() \n",
    "    \n",
    "    @staticmethod\n",
    "    def upper(data):\n",
    "        if(data == '' or data == None):\n",
    "            return None\n",
    "        else:\n",
    "            return str(data).upper()     \n",
    "    \n",
    "    @staticmethod\n",
    "    def replaceNaN(data):\n",
    "        if(np.isnan(data)): \n",
    "            return None\n",
    "        else:\n",
    "            return data\n",
    "    \n",
    "    # Python does not have switch statment, rather use dict approach\n",
    "    parser = {\n",
    "            'int':parse_int,\n",
    "            'date':parse_date,\n",
    "            'bool':parse_bool\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FILE_MAPPINGS = {\n",
    "'title.basics.tsv': {\n",
    "      'index_col': None, \n",
    "      'dtype' : {'tconst':np.dtype('S'),\n",
    "                 'titleType':np.dtype('S'), \n",
    "                 'primaryTitle':np.dtype('S'),\n",
    "                 'originalTitle':np.dtype('S'),\n",
    "                 'isAdult':np.dtype('S'),\n",
    "                 'startYear':np.dtype('S'),\n",
    "                 'endYear':np.dtype('S'),             \n",
    "                 'runtimeMinutes':np.dtype('S'),\n",
    "                 'genres':np.dtype('S')\n",
    "                    },      \n",
    "      'filePath':LESSON_DATA_FOLDER + 'title.basics.tsv',\n",
    "      'to_replace':{\n",
    "          'titleType':{'\\\\N':None},\n",
    "          'primaryTitle':{'\\\\N':None},\n",
    "          'originalTitle':{'\\\\N':None},\n",
    "          'startYear':{'\\\\N':None},\n",
    "          'endYear':{'\\\\N':None},\n",
    "          'runtimeMinutes':{'\\\\N':None}\n",
    "      },\n",
    "     'true_values':['1'],\n",
    "     'false_values':['0'],     \n",
    "     'usecols':['tconst','titleType','primaryTitle','originalTitle','isAdult',\n",
    "                'startYear','endYear','runtimeMinutes','genres'],\n",
    "     'converters' : {\n",
    "                 #'primaryTitle':[{'function':Utils.lower, 'args':None}],\n",
    "                 'titleType':[{'function':Utils.lower, 'args':None}],\n",
    "                 #'originalTitle':[{'function':Utils.lower, 'args':None}],\n",
    "                 'isAdult':[{'function':Utils.parse_bool, 'args':None}],\n",
    "                 'startYear':[{'function':Utils.parse_int, 'args':None}] ,\n",
    "                 'endYear':[{'function':Utils.parse_int, 'args':None}]  ,\n",
    "                 'runtimeMinutes':[{'function':Utils.parse_int, 'args':None}],\n",
    "                 'genres': [{'function':Utils.split, 'args':(',',)}]\n",
    "                 \n",
    "                }\n",
    "    },\n",
    "'title.crew.tsv': {\n",
    "      'index_col': None, \n",
    "      'dtype' : {'tconst':np.dtype('S'),'directors':np.dtype('S') ,'writers':np.dtype('S')  },\n",
    "      'split' : ['directors','writers'],\n",
    "      'filePath':LESSON_DATA_FOLDER + 'title.crew.tsv',\n",
    "      'to_replace':{\n",
    "          'directors':{'\\\\N':None},\n",
    "          'writers':{'\\\\N':None},          \n",
    "      },\n",
    "     'true_values':None,\n",
    "     'false_values':None,     \n",
    "     'usecols': None,\n",
    "     'converters' : {                 \n",
    "                 'writers':[{'function':Utils.split, 'args':(',',)}],\n",
    "                 'directors': [{'function':Utils.split, 'args':(',',)}]\n",
    "                }\n",
    "    }, \n",
    "'title.episode.tsv': {\n",
    "      'index_col': None, \n",
    "      'dtype' : {'tconst':np.dtype('S'),\n",
    "                 'parentTconst':np.dtype('S'),\n",
    "                 'seasonNumber':np.dtype('S'),  \n",
    "                 'episodeNumber':np.dtype('S')  \n",
    "                },\n",
    "      'split' :None,\n",
    "      'filePath':LESSON_DATA_FOLDER + 'title.episode.tsv',\n",
    "      'to_replace':{\n",
    "          'seasonNumber':{'\\\\N':None},\n",
    "          'episodeNumber':{'\\\\N':None},                   \n",
    "      },\n",
    "      'true_values':None,\n",
    "      'false_values':None,      \n",
    "      'usecols': None,\n",
    "      'converters' : {                 \n",
    "                 'seasonNumber':[{'function':Utils.parse_int, 'args':None}],\n",
    "                 'episodeNumber': [{'function':Utils.parse_int, 'args':None}]\n",
    "                }\n",
    "    },\n",
    "'title.principals.tsv': {\n",
    "      'index_col': None, \n",
    "      'dtype' : {'tconst':np.dtype('S'),\n",
    "                 'ordering':np.dtype('S'),\n",
    "                 'nconst':np.dtype('S'),\n",
    "                 'category':np.dtype('S'),\n",
    "                 'job':np.dtype('S'),                 \n",
    "                 'characters':np.dtype('S'),                 \n",
    "                },\n",
    "      'split' : None,\n",
    "      'filePath':LESSON_DATA_FOLDER + 'title.principals.tsv',\n",
    "      'to_replace':{\n",
    "          'job':{'\\\\N':None},\n",
    "          'characters':{'\\\\N':None},                   \n",
    "      },\n",
    "      'true_values':None,\n",
    "      'false_values':None,\n",
    "      'converters' : {                 \n",
    "                 'ordering':[{'function':Utils.parse_int, 'args':None}]             \n",
    "                },\n",
    "      'usecols': None      \n",
    "    },    \n",
    "'title.ratings.tsv': {\n",
    "      'index_col': None, \n",
    "      'dtype' : {'tconst':np.dtype('S'),'averageRating':np.float64 ,'numVotes':np.int32  },\n",
    "      'split' :None,\n",
    "      'filePath':LESSON_DATA_FOLDER + 'title.ratings.tsv',\n",
    "      'to_replace':None,\n",
    "      'true_values':None,\n",
    "      'false_values':None,      \n",
    "      'usecols': None,\n",
    "      'converters' : {                 \n",
    "                 'numVotes':[{'function':Utils.parse_int, 'args':None}]               \n",
    "                }    \n",
    "    },  \n",
    "'name.basics.tsv': {\n",
    "      'index_col': None, \n",
    "      'dtype' : {'nconst':np.dtype('S'),\n",
    "                 'primaryName':np.dtype('S') ,\n",
    "                 'birthYear':np.dtype('S')  ,\n",
    "                 'deathYear':np.dtype('S'),\n",
    "                 'primaryProfession':np.dtype('S'),\n",
    "                 'knownForTitles':np.dtype('S')\n",
    "                },      \n",
    "      'filePath':LESSON_DATA_FOLDER + 'name.basics.tsv',\n",
    "      'to_replace':{\n",
    "          'primaryProfession':{'\\\\N':None},\n",
    "          'knownForTitles':{'\\\\N':None},    \n",
    "          'birthYear':{'\\\\N':0},    \n",
    "          'deathYear':{'\\\\N':0},       \n",
    "      },\n",
    "      'true_values':None,\n",
    "      'false_values':None,\n",
    "      'usecols': None,    \n",
    "      'converters' : {                 \n",
    "             #'primaryName':[{'function':Utils.lower, 'args':None}],                 \n",
    "             'birthYear':[{'function':Utils.parse_int, 'args':(0,)}],                 \n",
    "             'deathYear':[{'function':Utils.parse_int, 'args':(0,)}],\n",
    "             'primaryProfession' :[{'function':Utils.split, 'args':(',',)}],\n",
    "             'knownForTitles':[{'function':Utils.split, 'args':(',',)}],          \n",
    "            } \n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def getMapping(file):\n",
    "    return FILE_MAPPINGS.get(file)\n",
    "\n",
    "def callFunction(columnData, **funDict):\n",
    "    \n",
    "    converFuns = funDict[columnData.name] #[{'function':split, 'args':(',')}]\n",
    "    \n",
    "    if(converFuns != None):\n",
    "        for funSpec in converFuns:\n",
    "            params = funSpec['args']\n",
    "            #print ('args: ', params, ' <> ', params == None)\n",
    "            if(params == None):                \n",
    "                columnData = columnData.apply(funSpec['function'] )\n",
    "            else:            \n",
    "                columnData = columnData.apply(funSpec['function'], args=params )\n",
    "            \n",
    "    return columnData\n",
    "\n",
    "def readFile(file, nrows=None, cluster=None ):   \n",
    "    print ('Start: ' + time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    mapping = getMapping(file)\n",
    "    dtype = mapping['dtype']\n",
    "    usecols = list(dtype.keys())\n",
    "    if(cluster != None):\n",
    "        dview = cluster[:]\n",
    "        dview.scatter(\n",
    "            \"df\", \n",
    "            pandas.read_table(mapping['filePath'], \n",
    "                           index_col=mapping['index_col'], \n",
    "                           dtype = dtype, \n",
    "                           #na_values = ['//N'],\n",
    "                           true_values= mapping['true_values'],\n",
    "                           false_values= mapping['false_values'],                       \n",
    "                           usecols=usecols,\n",
    "                           nrows =nrows \n",
    "                          )\n",
    "        )\n",
    "        df = pandas.concat([i for i in dview[\"df\"]])\n",
    "    else:\n",
    "        df = pandas.read_table(mapping['filePath'], \n",
    "                           index_col=mapping['index_col'], \n",
    "                           dtype = dtype, \n",
    "                           #na_values = ['//N'],\n",
    "                           true_values= mapping['true_values'],\n",
    "                           false_values= mapping['false_values'],                       \n",
    "                           usecols=usecols,\n",
    "                           nrows =nrows \n",
    "                          )\n",
    "        \n",
    "    \n",
    "    df.fillna(method='pad', inplace=True)\n",
    "    if(mapping['to_replace']!= None):\n",
    "        df.replace(to_replace=mapping['to_replace'],method='pad', inplace=True)\n",
    "    \n",
    "    converters = mapping['converters']\n",
    "    if(converters!= None):\n",
    "        cols = list(converters.keys())\n",
    "        df[cols] = df[cols].apply(callFunction, **converters)\n",
    "        \n",
    "    print ('End: ' + time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hub connection request timed out\n",
      "Start: 2018-03-02 16:54:28\n",
      "End: 2018-03-02 16:54:28\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class 'UnicodeEncodeError'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xf3' in position 4: ordinal not in range(128)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mSystemError\u001b[0m: <class 'UnicodeEncodeError'> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mSystemError\u001b[0m: <class 'UnicodeEncodeError'> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d1a981e7425f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m                      \u001b[1;31m#'wikipedia':np.dtype('S1000'),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                      \u001b[1;34m'lastName'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'S100'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                      \u001b[1;34m'firstName'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'S100'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                 })\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   3995\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3996\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3998\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3999\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   4002\u001b[0m         \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4003\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 4004\u001b[1;33m                                      **kwargs)\n\u001b[0m\u001b[0;32m   4005\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   3460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3462\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3328\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3329\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3330\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 544\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class 'UnicodeEncodeError'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "names = readFile('name.basics.tsv', nrows=100, cluster=ParallelUtil().getCluster())\n",
    "names['isAlive'] = names['deathYear'] == 0\n",
    "\n",
    "def wikiLink(name):\n",
    "    link = ''.join (['https://en.wikipedia.org/wiki/', ''.join ([n + '_' for n in name.split()])]).rstrip('_')    \n",
    "    return link\n",
    "\n",
    "names['wikipedia'] = names['primaryName'].apply(wikiLink)\n",
    "names[['lastName', 'firstName']] = names['primaryName'].apply(lambda x: pd.Series(str(x).lower().split(' ', 1)))\n",
    "                       \n",
    "def age(data):\n",
    "    if(data['deathYear'] == 0):\n",
    "        return 2017 - data['birthYear']\n",
    "    else:\n",
    "        return data['deathYear'] - data['birthYear']\n",
    "            \n",
    "names['age'] = names[['deathYear', 'birthYear']].apply(age, axis = 1)\n",
    "\n",
    "names = names.astype({\n",
    "                    'nconst':np.dtype('S20'),\n",
    "                     'primaryName':np.dtype('S200') ,\n",
    "                     'birthYear':np.int64  ,\n",
    "                     'deathYear':np.int64,\n",
    "                     'primaryProfession':np.dtype('S200'),\n",
    "                     #'wikipedia':np.dtype('S1000'),\n",
    "                     'lastName':np.dtype('S100'),\n",
    "                     'firstName':np.dtype('S100'),\n",
    "                })\n",
    "\n",
    "\n",
    "names.info()\n",
    "#ddf = dd.from_pandas(names, npartitions=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "      <th>isAlive</th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>lastName</th>\n",
       "      <th>firstName</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899</td>\n",
       "      <td>1987</td>\n",
       "      <td>[soundtrack, actor, miscellaneous]</td>\n",
       "      <td>[tt0050419, tt0072308, tt0043044, tt0053137]</td>\n",
       "      <td>False</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fred_Astaire</td>\n",
       "      <td>fred</td>\n",
       "      <td>astaire</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>1924</td>\n",
       "      <td>2014</td>\n",
       "      <td>[actress, soundtrack]</td>\n",
       "      <td>[tt0117057, tt0037382, tt0040506, tt0038355]</td>\n",
       "      <td>False</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lauren_Bacall</td>\n",
       "      <td>lauren</td>\n",
       "      <td>bacall</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>1934</td>\n",
       "      <td>0</td>\n",
       "      <td>[actress, soundtrack, producer]</td>\n",
       "      <td>[tt0049189, tt0063715, tt0059956, tt0057345]</td>\n",
       "      <td>True</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Brigitte_Bardot</td>\n",
       "      <td>brigitte</td>\n",
       "      <td>bardot</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>1949</td>\n",
       "      <td>1982</td>\n",
       "      <td>[actor, writer, soundtrack]</td>\n",
       "      <td>[tt0072562, tt0080455, tt0078723, tt0077975]</td>\n",
       "      <td>False</td>\n",
       "      <td>https://en.wikipedia.org/wiki/John_Belushi</td>\n",
       "      <td>john</td>\n",
       "      <td>belushi</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>1918</td>\n",
       "      <td>2007</td>\n",
       "      <td>[writer, director, actor]</td>\n",
       "      <td>[tt0050986, tt0050976, tt0083922, tt0060827]</td>\n",
       "      <td>False</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ingmar_Bergman</td>\n",
       "      <td>ingmar</td>\n",
       "      <td>bergman</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst      primaryName  birthYear  deathYear  \\\n",
       "0  nm0000001     Fred Astaire       1899       1987   \n",
       "1  nm0000002    Lauren Bacall       1924       2014   \n",
       "2  nm0000003  Brigitte Bardot       1934          0   \n",
       "3  nm0000004     John Belushi       1949       1982   \n",
       "4  nm0000005   Ingmar Bergman       1918       2007   \n",
       "\n",
       "                    primaryProfession  \\\n",
       "0  [soundtrack, actor, miscellaneous]   \n",
       "1               [actress, soundtrack]   \n",
       "2     [actress, soundtrack, producer]   \n",
       "3         [actor, writer, soundtrack]   \n",
       "4           [writer, director, actor]   \n",
       "\n",
       "                                 knownForTitles  isAlive  \\\n",
       "0  [tt0050419, tt0072308, tt0043044, tt0053137]    False   \n",
       "1  [tt0117057, tt0037382, tt0040506, tt0038355]    False   \n",
       "2  [tt0049189, tt0063715, tt0059956, tt0057345]     True   \n",
       "3  [tt0072562, tt0080455, tt0078723, tt0077975]    False   \n",
       "4  [tt0050986, tt0050976, tt0083922, tt0060827]    False   \n",
       "\n",
       "                                       wikipedia  lastName firstName  age  \n",
       "0     https://en.wikipedia.org/wiki/Fred_Astaire      fred   astaire   88  \n",
       "1    https://en.wikipedia.org/wiki/Lauren_Bacall    lauren    bacall   90  \n",
       "2  https://en.wikipedia.org/wiki/Brigitte_Bardot  brigitte    bardot   83  \n",
       "3     https://en.wikipedia.org/wiki/John_Belushi      john   belushi   33  \n",
       "4   https://en.wikipedia.org/wiki/Ingmar_Bergman    ingmar   bergman   89  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# title.crew.tsv => many not need this file as title.principal.tsv \n",
    "crew = readFile('title.crew.tsv', 10000)#.compute()\n",
    "crew.info()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "title_writers = explode(crew, ['writers'], fill_value='')\n",
    "title_writers.drop('directors', axis=1, inplace=True)\n",
    "#title_writers.info()\n",
    "title_writers.rename(columns={'writers': 'nconst'}, inplace=True)\n",
    "title_writers.columns\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "title_directors = explode(crew, ['directors'], fill_value='')\n",
    "title_directors.drop('writers', axis=1, inplace=True)\n",
    "#title_directors.info()\n",
    "\n",
    "title_directors.rename(columns={'directors': 'nconst'}, inplace=True)\n",
    "title_directors.columns\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "title_writers = title_writers.merge(names, on=['nconst'])\n",
    "title_writers.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "title_directors = title_directors.merge(names, on=['nconst'])\n",
    "title_directors.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#title_writers.replace(to_replace={'knownForTitles':{np.NaN:None}},inplace=True)\n",
    "#title_grouped_directors = \n",
    "title_grouped_directors = title_directors.head(10000).groupby('tconst')#.apply(f)\n",
    "title_grouped_directors\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    #@dview.parallel(block=True)\n",
    "    def f(group):\n",
    "        #print (len(group))\n",
    "\n",
    "        #group = pandas.DataFrame(group.to_dict('dict'))\n",
    "\n",
    "        group = group.set_index('tconst')    \n",
    "        data = {'directors': group.to_json(orient='records')}\n",
    "        #data = {'directors': group.to_dict('dict')}\n",
    "        #print (group.index.values , directors)\n",
    "        return pandas.DataFrame(data=data, index = group.index.values)  \n",
    "\n",
    "\n",
    "\n",
    "#title_grouped_directors# = \n",
    "#title_grouped_directors.reset_index().drop(['level_1'], axis= 1)\n",
    "#pd.DataFrame(title_grouped_directors).to_json(orient='records')\n",
    "#title_grouped_directors.reset_index(level='tconst')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print (time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "clusters = PARALLEL_CLUSTERS()\n",
    "dview = clusters[:]\n",
    "dview.scatter(\"scview\", title_grouped_directors.apply(f))\n",
    "#dview['scview']\n",
    "title_grouped_directors = pd.concat([i for i in dview[\"scview\"]])\n",
    "print (time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#title_grouped_directors = title_grouped_directors.reset_index().drop(['level_1'], axis= 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = readFile('title.ratings.tsv')\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = readFile('title.basics.tsv', 10000)\n",
    "titles['wikipedia'] = titles['primaryTitle'].apply(wikiLink)\n",
    "#titles.tail()\n",
    "#titles[titles['primaryTitle'] != titles['originalTitle']][['wikipedia','originalTitle','primaryTitle']].to_dict('record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titles = titles.merge(ratings, on=['tconst'])\n",
    "#titles[titles['primaryTitle'] != titles['originalTitle']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesp = pandas.read_table('./data/title.principals.tsv',nrows =1000) \n",
    "titlesc = pandas.read_table('./data/title.crew.tsv',nrows =1000) \n",
    "\n",
    "titlesc[titlesc['writers'] != '\\\\N']\n",
    "\n",
    "#titlesc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesp[titlesp['tconst'] == 'tt0000076']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names.info()\n",
    "#del names\n",
    "'''Important '''\n",
    "#names.loc[['nm0000001'],['primaryName','birthYear','deathYear','primaryProfession']].to_dict('index')\n",
    "\n",
    "\n",
    "del titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series({'aa':0, 'ba':1,'ca':2})\n",
    "s2 = pd.Series({'ab':3, 'bb':4,'cb':5})\n",
    "\n",
    "\n",
    "df = pd.DataFrame (data={\n",
    "    'a':[1,2],\n",
    "    'x':[s1,s2],\n",
    "    'y':[['aa','ba','ca'],['ab','bb','cb']],\n",
    "    'z':['a,b,c', 'd,e,f']\n",
    "})\n",
    "#df.iloc[0:].to_json(orient='records')\n",
    "split_data = df['z'].str.split(',').apply(pd.Series, 1).stack()\n",
    "#df_new.index\n",
    "split_data.index = split_data.index.droplevel(-1)\n",
    "split_data\n",
    "df = df.join (pd.DataFrame(split_data))\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'directors': '[{\"tconst\":\"tt8046488\",\"nconst\":\"nm9649918\",\"primaryName\":\"ricky capo\",\"birthYear\":0,\"deathYear\":0,\"knownForTitles\":[null]}]'}, index=['tt8046488'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([1,3.09])\n",
    "df[0] = df[0].apply(np.int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_series = df['Ticket'].str.split(' ').apply(pd.Series, 1).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
